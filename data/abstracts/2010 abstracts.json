[
    {
        "abstract": "This work describes a model whose main objective is to storehistoric data, resulting in the Analytic-Temporal Databases. This model canaid in the design and implementation of the Analytic-Temporal Databases thatconstitutes a very adequate foundation to help in the decision taking process,audits and data recovery. This work contains two stages. The first stage aimsto manually help the modeling of Analytical-Temporal Database, based onmodels of data from Operational Databases. The second stage aims to provideautomatic mechanisms, used in Database Management Systems, providinggeneration and storage of analytical-temporal data, using triggers and storedprocedures.",
        "resumo": "O presente trabalho descreve um modelo para, projetar eimplementar Bancos de Dados Analítico-Temporais, cujo principal objetivo éo de armazenar históricos de dados para auxiliar no processo de tomada dedecisões, auditorias e recuperação de dados. O trabalho contém duas etapas.A primeira etapa tem por objetivo auxiliar, manualmente, a modelagem doBanco de Dados Analítico-Temporal, com base nos modelos de dados dosBancos de Dados Operacionais. Na segunda etapa objetivou-se disponibilizarmecanismos automáticos, explorados nos próprios Sistemas Gerenciadores deBanco de Dados, que possibilitem a geração e o armazenamento dos dadosAnalítico-Temporais, usando gatilhos e procedimentos armazenados."
    },
    {
        "abstract": "Most XML documents, which have historical information, do not fol-low a temporal data model, i.e., they are documents that reflect an ad-hoc tem-poral model that have neither time constraints control nor temporal query lan-guages support. This paper presents a proposal for automatic mapping of XMLad-hoc temporal data models to a standard temporal data model, in order toallow temporal queries. Among the contributions, we highlight the automaticmapping and the implementation of a prototype, called AXPath, for annotatingtemporal paths. Our initial experiments show that the AXPath prototype produ-ces better results of precision than the related works.",
        "resumo": "Grande parte dos documentos XML, que possui informações histó-ricas, não segue um modelo de dados temporal, ou seja, são documentos querefletem um modelo temporal ad-hoc que não possui controle das restrições detempo nem suporta linguagens de consulta temporal. Este trabalho apresentauma proposta de mapeamento automático de modelos de dados XML temporaisad-hoc para um modelo de dados XML temporal padrão, a fim de permitir arealização de consultas temporais. Dentre as contribuições, destacam-se o ma-peamento automático e a implementação do protótipo AXPath para anotaçãode caminhos temporais. Experimentos iniciais mostram que o protótipo AXPathapresenta melhores resultados de precisão que os trabalhos relacionados."
    },
    {
        "abstract": "Even though the oral health literature presents many works relatedto the generation and application of models for predicting pathologies, most ofthem concentrate on maximizing predictive accuracy, ignoring important issuessuch as result interpretation and validation. The goal of this work is to discussthe advantages of generating comprehensible models that can be interpreted bythe domain specialist. For this purpose, it is presented a comparison of differenttechniques applied to an oral health problem in order to validate the conceptsunder discussion.",
        "resumo": "Embora a literatura de saúde bucal disponibilize uma série de tra-balhos relacionados à exploração de modelos preditivos para as mais diversaspatologias bucais, boa parte destes trabalhos está eminentemente orientada amaximização da acurácia preditiva, desprezando aspectos importantes como avalidação e interpretação dos resultados obtidos. Este trabalho tem como ob-jetivo discutir em detalhes as vantagens de se gerar modelos compreensı́veispara o especialista de domı́nio e, para tanto, apresenta uma comparação dediferentes abordagens preditivas sobre um problema de saúde bucal, de formaa validar os conceitos discutidos."
    },
    {
        "abstract": "This paper presents a proposal of a taxonomy to be used for definingmulti-faced metadata in a data integration environment. The main idea is todefine this taxonomy in levels, where the more abstract one may be classifiedin: syntactic, structural and semantic. Our proposal is based on the idea ofmulti-faced classification, where a specific metadata must appear in morethan one classification.",
        "resumo": "Este artigo descreve a especificação de uma taxononomia a serusada para definição de metadados multifacetados utilizados em ambientes deintegração de dados na Web. A idéia principal é definir a taxonomia emníveis, onde o nível mais abstrato pode ser classificado em: sintático,estrutural e semântico. A proposta é baseada na idéia de classificaçãomultifacetada, onde um mesmo metadado pode aparecer em mais de umaclassificação."
    },
    {
        "abstract": "This paper describes the knowledge-based interface of S2DW, asystem that uses ontologies to support information analysis in spatial datawarehouses (SDWs). S2DW uses a domain ontology and an ontology ofstructures and resources for data manipulation in SDWs to semanticallydescribe them. It supports searching for descriptions of SDWs related to sometheme using domain-specific vocabulary, and allows the user to interact withsuch descriptions to specify SOLAP(Spatial OLAP) queries on the retrievedSDWs. The tables, graphs and maps generated by the system in response tosuch queries support additional SOLAP interactions.",
        "resumo": "Este trabalho descreve a interface baseada em conhecimento doS2DW, um sistema que usa ontologias para suportar análises de informaçãoem data warehouses espaciais (SDWs). O S 2DW usa uma ontologia dedomínio e uma ontologia de estruturas e recursos de manipulação de dadosem SDWs para descrevê-los semanticamente. Ele suporta buscas pordescrições de SDWs relacionados a algum tema, usando vocabulárioespecífico de domínio, e permite ao usuário interagir com tais descrições paraespecificar consultas SOLAP sobre os SDWs correspondentes. As tabelas,gráficos e mapas gerados pelo sistema em atendimento a tais consultassuportam interações adicionais de OLAP espacial."
    },
    {
        "abstract": "The Oracle database management system owns an internal query op-timizer that generates an execution plan to each query that is executed. Thisexecution plan is stored in a specific table (plan table) and contains informa-tion on the operations that were executed, on the order they occur and on theoperational cost of each of them. Properly understanding this execution planenables the user to optimize each query once he knows a few optimization rules.The goal of this work is to facilitate both the visualization of the execution planand its analysis.",
        "resumo": "O Sistema de Gerenciamento de Banco de Dados Oracle possui umotimizador interno de consultas que gera um plano de execução para cada con-sulta executada. Esse plano é armazenado em uma tabela especial (plan table)que contém informações quanto às operações executadas, à ordem em que elasacontecem e ao custo operacional de cada uma. O entendimento desse planode execução de consultas auxilia o usuário a otimizá-las, mas, para isso, esteprecisa conhecer algumas regras de otimização. O objetivo deste trabalho é fa-cilitar tanto a visualização do plano de execução de consultas quanto a análisedeste."
    },
    {
        "abstract": "The structured and semi-strucutured data sources integration is amajor challenge for the database area. The objective of this paper is topresent a tool capable to achieve integration and enable the identification ofduplicates in structured and semi-strucutured data sources.",
        "resumo": "A integração de fontes de dados estruturadas e semi-estruturadas éum dos grandes desafios para a área de banco de dados. O objetivo destetrabalho é apresentar uma proposta de ferramenta para realizar a integraçãoe permitir a identificação de duplicatas em fontes de dados estruturadas esemi-estruturadas."
    },
    {
        "abstract": "The need for efficiency in the institutions’ decision process requiresthe use of solutions that generate consistent information. BI (Business Intelli-gence) tools come to address this matter. An initial matter in any BI projectis choosing support tools to be used in the development process. This paperpresents a case study made at UFBA with comparative analysis between twoBI tools: a free software solution (Pentaho) and a proprietary solution (Mi-crosoft). The same project was developed in both suites, using a real databasefrom UFBA. Also, various criteria for analysis were defined and categorized.These criteria assisted in the definition of user profiles that helped determinethe most suitable solution for each institution.",
        "resumo": "A necessidade de eficiência no processo decisório das instituiçõesexige a utilização de soluções que gerem informações consistentes. É nesse con-texto que se inserem as ferramentas de BI (Business Intelligence).Uma questãoinicial em qualquer projeto de BI é a escolha do ferramental de apoio a serusado no desenvolvimento.Este artigo apresenta um estudo de caso realizadona UFBA com análise comparativa entre duas ferramentas de BI: uma soluçãolivre (Pentaho) e outra proprietária (Microsoft). Desenvolveu-se um mesmo pro-jeto em ambas, usando dados reais da UFBA, e foram definidos e categorizadoscritérios para análise. Esses critérios permitiram definir perfis de usuários queapóiem a definição da ferramenta mais adequada para cada instituição."
    },
    {
        "abstract": "This paper describes the use of data mining in order to extractinteresting rules from a database of service orders. The rules obtained areconsidered relevant to the strategic decisions that can improve theperformance of maintenance services.",
        "resumo": "Este artigo descreve o uso de mineração de dados com o objetivo deextrair regras interessantes de uma base de dados de ordens de serviço. Asregras obtidas são consideradas relevantes para a tomada de decisõesestratégicas que podem melhorar o desempenho dos serviços de manutenção."
    },
    {
        "abstract": "The paper describes the query module of the CERES System. CERES is an ExpertSystem based in ontology that automate the activities of interpretation of the soil proprietiesand recommends the use of fertilizing, when necessary. Among the requirements of theapplication domain, includes to retrieve historical data about the soil conditions. In thisway, a model capable of storing temporal data in the database has been defined. Also, aninterface supports the querying process and allows the expert system to define selectionexpressions based on soil characteristics. The interface consists in a relevant tool to thesystem.",
        "resumo": "Este artigo apresenta o módulo de consultas do sistema CERES. CERES é umsistema especialista baseado em ontologia que suporta o processo de interpretação erecomendação de adubação e calagem de solo. Dentre os requisitos da aplicação inclui-sea recuperação de dados históricos sobre as condições do solo. Desta forma, tem sidodefinido um modelo capaz de armazenar dados temporais. O processo de consulta propostopermite ao especialista definir expressões de seleção baseados em características dasamostras de solo e consiste em uma relevante ferramenta para o sistema."
    },
    {
        "resumo": "Grande parte das instituições de ensino superior ainda utilizam o mo-delo ER no ensino de modelagem de dados conceitual. Contudo, nota-se umacarência em relação a ferramentas que reflitam exatamente o que é ensinado emsala de aula. A partir dessa motivação, este artigo descreve as funcionalidadese vantagens da utilização da ferramenta TerraER no ensino de disciplinas deBanco de Dados em cursos de graduação. Além disso, são relatados resultadosdemonstrando uma forte aceitação por parte dos professores e alunos."
    },
    {
        "resumo": "Uma das tendências da Web atual é a crescente utilização deconteúdo marcado semanticamente, possibilitando que as informações daspáginas sejam facilmente processadas por agentes de software. A criaçãomanual necessita ser feita pelo usuário final, que na maioria das vezes nãopossui qualquer conhecimento sobre as tecnologias envolvidas. Portanto, sãonecessárias ferramentas que facilitem o processo de autoria de marcaçãosemântica de dados para estes usuários. Neste trabalho, depois da análise dediversas soluções encontradas, é proposta e desenvolvida a ferramenta deautoria EdMaSe, com o objetivo de facilitar ainda mais este processo."
    },
    {
        "abstract": "Inherently to current large databases, there are some problems suchas null values, missing values, duplicated tuples, outliers and others, ifuntreated, can affect the reliability of the knowledge extracted in the KDDprocess. Thus, there is a step in this process called “data cleaning” whichmust be performed before the stage of data mining and is responsible for tasksof correction and adjustment in the data. The tool proposed here focuses onthat stage and implements some of the existing techniques for handling theseproblems in order to ensure greater consistency and reliability of the data thatare used as raw for data mining.",
        "resumo": "Inerentemente às grandes bases de dados atuais, existem algunsproblemas tais como valores nulos, valores ausentes, tuplas duplicadas,valores fora de domínio, entre outros, que, se não tratados, podem prejudicara confiabilidade do conhecimento extraído no processo de KDD. Para isso,existe uma etapa nesse processo denominada “limpeza de dados”, que deveser executada antes da etapa de data mining e que é responsável por realizarcorreções e ajustes nos dados. A ferramenta, aqui apresentada, foca nessaetapa e implementa algumas das técnicas existentes para tratamento dessesproblemas, visando garantir uma maior consistência e confiabilidade nosdados que serão utilizados como alvo na mineração de dados."
    },
    {
        "resumo": "Este trabalho realiza análises sobre ações da BOVESPA aplicandotécnicas de classificação de Data Mining. Dessa forma, foi possível extrairconhecimento útil e válido para investidores. Foi desenvolvida uma aplicaçãoque resultou na classificação das ações de uma bolsa de valores, utilizandoum algoritmo conhecido como Nearest Neighbors, onde foi possível obterbons resultados em comparação a um método utilizado cotidianamente poranalistas de ações, que é o método de Médias Móveis."
    },
    {
        "abstract": "This paper presents a precision agriculture web application usingspatial database as basis for handling georeferenced information ofagricultural yield data. Open technologies and standards were used in orderto facilitate the map generation and integration of specialized softwareartifacts.",
        "resumo": "Este artigo apresenta uma aplicação web para agricultura deprecisão que utiliza banco de dados espacial como base para manipulação deinformações de produtividade agrícola georeferenciadas. Tecnologias epadrões abertos foram utilizados com o objetivo de facilitar a geração demapas e integração de artefatos de software especializados."
    },
    {
        "resumo": "Este artigo apresenta uma ferramenta para gerar bancos de dadosgeográficos a partir de um diagrama OMT-G criado no software Star UML.Inicialmente, é apresentado um modelo genérico de mapeamento de elementos domodelo OMT-G para elementos correspondentes em um banco de dados objeto-relacional para, em seguida, apresentar a ferramenta proposta. Ao final, asconsiderações finais retratam o estado atual do projeto e desenvolvimentos futuros."
    },
    {
        "abstract": "The paper presents StereoMap, a web application for searchingmusical events by locality. It was developed as a mashup, i.e., by integratingdata and services provided by external sources. StereoMap has fourdata/service providers: Last.fm, Google Maps, Twitter, and Wikipedia.Mashup applications have become a technological trend to develop integratedservices and to provide more flexibility for the end user.",
        "resumo": "Este artigo apresenta uma aplicação web que permite a busca deeventos musicais por localidade, chamada StereoMap. Ela foi desenvolvidautilizando o conceito de mashup, ou seja, através da integração de serviços edados provenientes de diversas fontes. O StereoMap utiliza como provedoresde conteúdo os seguintes serviços: Last.fm, Google Maps, Twitter eWikipedia. Os mashups estão se tornando uma tendência tecnológica,facilitando o desenvolvimento de serviços integrados e proporcionando maiorflexibilidade ao usuário final"
    }
]